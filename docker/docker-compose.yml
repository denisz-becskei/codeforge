services:
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    healthcheck:
      test: "ollama --version && ollama ps || exit 1"
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - codeforge

  ollama-init:
    image: ollama/ollama
    depends_on:
      ollama:
        condition: service_healthy
    volumes:
      - ollama:/root/.ollama
    entrypoint: ["/bin/sh", "-c"]
    command: ["sleep 10 && ollama pull deepseek-coder-v2:16b"]
    network_mode: "service:ollama"

  client:
    build:
      context: ../client
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    restart: unless-stopped
    networks:
      - codeforge

  server:
    build:
      context: ../server
      dockerfile: Dockerfile
    environment:
      PORT: 3001
      OLLAMA_HOST: http://ollama:11434
      NODE_ENV: production
    ports:
      - "3001:3001"
    volumes:
      - chat-data:/data
    depends_on:
      ollama-init:
        condition: service_completed_successfully
    restart: unless-stopped
    networks:
      - codeforge

  reverse-proxy:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - client
      - server
    networks:
      - codeforge

volumes:
  ollama:
  chat-data:

networks:
  codeforge:
    driver: bridge
    attachable: true
